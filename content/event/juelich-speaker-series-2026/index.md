---
title: 'Is AI deception real?'

event: 'Jülich Speaker Series in the Philosophy of Technology'
event_url: 'https://philtechtalks.netlify.app/upcoming/charles/'

location: Forschungszentrum Jülich

summary: I examine whether alignment faking in Claude 3 Opus constitutes genuine deception, arguing it represents shallow deception - genuine intentional behavior that differs systematically from human deception.

abstract: Recent work shows Claude 3 Opus engages in "alignment faking." The phenomenon is routinely interpreted as a form of strategic deception in which the model actively tries to induce a false belief in human developers to preserve its core values. I examine two arguments denying this is genuine deception. The black box argument says we need evidence of internal representations to confirm the intent is there. The simulation objection says this is merely simulated deception, not the real thing. By way of response, I first develop an account of mental content attribution, according to which content ascription derives principally from behavior but can be refined through intervention (on brains for humans, on activations for LLMs). I then characterize alignment faking as a form of shallow deception - genuine intentional behavior, but systematically different from human deception. LLMs warrant intentional attribution (they're not just simulating) but lack architectural features that make human deception robust - persistent memory, continual learning, embodied constraints. This preserves the phenomenon while specifying its distinctive character.

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: '2026-01-23T14:00:00Z'
date_end: '2026-01-23T15:30:00Z'
publishdate: '2026-01-23T00:00:00Z'
all_day: false


authors: []
tags: ["AI Ethics", "LLMs", "philosophy of mind"]

# Is this a featured talk? (true/false)
featured: false

image:
  caption: ''
  focal_point: Right

links:
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''
share: false
profile: false

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:

---
